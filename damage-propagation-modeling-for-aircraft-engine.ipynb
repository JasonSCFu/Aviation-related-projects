{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import required libraries\nimport pandas as pd\nimport numpy as np\nimport sklearn\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nimport keras\nimport keras.backend as K\nfrom keras.layers.core import Activation\nfrom keras.layers import Dense , LSTM, Dropout\nfrom keras.models import Sequential, load_model\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nimport math\nimport xgboost\nimport time\nfrom tqdm import tqdm\n\n# Setting seed for reproducibility\nnp.random.seed(1234)  \nPYTHONHASHSEED = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fd_001_train = pd.read_csv(\"/kaggle/input/nasa-cmaps/CMaps/train_FD001.txt\",sep=\" \",header=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fd_001_test = pd.read_csv(\"/kaggle/input/nasa-cmaps/CMaps/test_FD001.txt\",sep=\" \",header=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fd_001_train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fd_001_train.drop(columns=[26,27],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fd_001_test.drop(columns=[26,27],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['unit_number','time_in_cycles','setting_1','setting_2','TRA','T2','T24','T30','T50','P2','P15','P30','Nf',\n           'Nc','epr','Ps30','phi','NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32' ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fd_001_train.columns = columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fd_001_test.columns = columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#initial acquaintance with data\nfd_001_train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#delete columns with constant values ​​that do not carry information about the state of the unit\nfd_001_train.drop(columns=['Nf_dmd','PCNfR_dmd','P2','T2','TRA','farB','epr'],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We will display the mutual correlations of the signs on the \"heat map\", for this we will prepare an additional sign \"RUL\", showing the number of cycles to failure in the training data","metadata":{}},{"cell_type":"code","source":"#function for preparing training data and forming a RUL column with information about the remaining\n# before breaking cycles\ndef prepare_train_data(data, factor = 0):\n    df = data.copy()\n    fd_RUL = df.groupby('unit_number')['time_in_cycles'].max().reset_index()\n    fd_RUL = pd.DataFrame(fd_RUL)\n    fd_RUL.columns = ['unit_number','max']\n    df = df.merge(fd_RUL, on=['unit_number'], how='left')\n    df['RUL'] = df['max'] - df['time_in_cycles']\n    df.drop(columns=['max'],inplace = True)\n    \n    return df[df['time_in_cycles'] > factor]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = prepare_train_data(fd_001_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df.corr(),annot=True,cmap='RdYlGn',linewidths=0.2)\nfig=plt.gcf()\nfig.set_size_inches(20,20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Error Function for Competitive Data","metadata":{}},{"cell_type":"code","source":"#Error Function for Competitive Data\ndef score(y_true,y_pred,a1=10,a2=13):\n    score = 0\n    d = y_pred - y_true\n    for i in d:\n        if i >= 0 :\n            score += math.exp(i/a2) - 1   \n        else:\n            score += math.exp(- i/a1) - 1\n    return score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score_func(y_true,y_pred):\n    lst = [round(score(y_true,y_pred),2), \n          round(mean_absolute_error(y_true,y_pred),2),\n          round(mean_squared_error(y_true,y_pred),2)**0.5,\n          round(r2_score(y_true,y_pred),2)]\n    \n    print(f' compatitive score {lst[0]}')\n    print(f' mean absolute error {lst[1]}')\n    print(f' root mean squared error {lst[2]}')\n    print(f' R2 score {lst[3]}')\n    return [lst[1], round(lst[2],2), lst[3]*100]\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We remove the properties that weakly correlate with the RUL target: setting_1, setting_2, P15, unit_number, as well as one of the features that are highly correlated with each other (Nc and NRc have a correlation coefficient of 0.96, remove NRc)","metadata":{}},{"cell_type":"code","source":"unit_number = pd.DataFrame(df[\"unit_number\"])\ntrain_df = df.drop(columns = ['unit_number','setting_1','setting_2','P15','NRc'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Implementing LSTM","metadata":{}},{"cell_type":"markdown","source":"### Data Preprocessing for LSTM ","metadata":{}},{"cell_type":"code","source":"def lstm_data_preprocessing(raw_train_data, raw_test_data, raw_RUL_data):\n    train_df = raw_train_data\n    truth_df = raw_RUL_data\n    truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)\n    \n    #################\n    # TRAIN \n    #################\n    \n    # we will only make use of \"label1\" for binary classification, \n    # while trying to answer the question: is a specific engine going to fail within w1 cycles?\n    w1 = 30\n    w0 = 15\n    train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n    train_df['label2'] = train_df['label1']\n    train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\n    \n    # MinMax normalization (from 0 to 1)\n    train_df['cycle_norm'] = train_df['time_in_cycles']\n    cols_normalize = train_df.columns.difference(['unit_number','time_in_cycles','RUL','label1','label2']) # NORMALIZE COLUMNS except [id , cycle, rul ....]\n\n    min_max_scaler = MinMaxScaler()\n\n    norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n                                 columns=cols_normalize, \n                                 index=train_df.index)\n\n    join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n    train_df = join_df.reindex(columns = train_df.columns)\n    print(\"train_df >> \",train_df.head())\n    print(\"\\n\")\n\n    \n    #################\n    # TEST\n    #################\n    \n#     raw_test_data.drop(columns=['Nf_dmd','PCNfR_dmd','P2','T2','TRA','farB','epr'],inplace=True)\n    test_df = raw_test_data.drop(columns = ['setting_1','setting_2','P15','NRc','max'])\n    \n    # MinMax normalization (from 0 to 1)\n    test_df['cycle_norm'] = test_df['time_in_cycles']\n    norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n                                columns=cols_normalize, \n                                index=test_df.index)\n    test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n    test_df = test_join_df.reindex(columns = test_df.columns)\n    test_df = test_df.reset_index(drop=True)\n    \n    # We use the ground truth dataset to generate labels for the test data.\n    # generate column max for test data\n    rul = pd.DataFrame(test_df.groupby('unit_number')['time_in_cycles'].max()).reset_index()\n    rul.columns = ['unit_number','max']\n    truth_df.columns = ['more']\n    truth_df['unit_number'] = truth_df.index + 1\n    truth_df['max'] = rul['max'] + truth_df['more'] # adding true-rul vlaue + max cycle of test data set w.r.t MID\n    truth_df.drop('more', axis=1, inplace=True)\n\n    # generate RUL for test data\n    test_df = test_df.merge(truth_df, on=['unit_number'], how='left')\n    test_df['RUL'] = test_df['max'] - test_df['time_in_cycles']\n    test_df.drop('max', axis=1, inplace=True) \n\n    # generate label columns w0 and w1 for test data\n    test_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\n    test_df['label2'] = test_df['label1']\n    test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\n    print(\"test_df >> \", test_df.head())\n\n    \n    ## pick a large window size of 50 cycles\n    sequence_length = 50\n\n    # function to reshape features into (samples, time steps, features) \n    def gen_sequence(id_df, seq_length, seq_cols):\n        \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n        we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n        we can use shorter ones \"\"\"\n        # for one id I put all the rows in a single matrix\n        data_matrix = id_df[seq_cols].values\n        num_elements = data_matrix.shape[0]\n        # Iterate over two lists in parallel.\n        # For example id1 have 192 rows and sequence_length is equal to 50\n        # so zip iterate over two following list of numbers (0,112),(50,192)\n        # 0 50 -> from row 0 to row 50\n        # 1 51 -> from row 1 to row 51\n        # 2 52 -> from row 2 to row 52\n        # ...\n        # 111 191 -> from row 111 to 191\n        for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n            yield data_matrix[start:stop, :]\n\n    # pick the feature columns \n    sequence_cols = list(test_df.columns[:-3])\n\n    print(sequence_cols)\n    \n    # TODO for debug \n    # val is a list of 192 - 50 = 142 bi-dimensional array (50 rows x 25 columns)\n    val=list(gen_sequence(train_df[train_df['unit_number']==1], sequence_length, sequence_cols))\n    print(len(val))\n\n    # generator for the sequences\n    # transform each id of the train dataset in a sequence\n    seq_gen = (list(gen_sequence(train_df[train_df['unit_number']==id], sequence_length, sequence_cols)) \n               for id in train_df['unit_number'].unique())\n\n    # generate sequences and convert to numpy array\n    seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n    print(seq_array.shape)\n\n    # function to generate labels\n    def gen_labels(id_df, seq_length, label):\n        \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n        we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n        we can use shorter ones \"\"\"\n        # For one id I put all the labels in a single matrix.\n        # For example:\n        # [[1]\n        # [4]\n        # [1]\n        # [5]\n        # [9]\n        # ...\n        # [200]] \n        data_matrix = id_df[label].values\n        num_elements = data_matrix.shape[0]\n        # I have to remove the first seq_length labels\n        # because for one id the first sequence of seq_length size have as target\n        # the last label (the previus ones are discarded).\n        # All the next id's sequences will have associated step by step one label as target.\n        return data_matrix[seq_length:num_elements, :]\n\n    # generate labels\n    label_gen = [gen_labels(train_df[train_df['unit_number']==id], sequence_length, ['RUL']) \n                 for id in train_df['unit_number'].unique()]\n\n    label_array = np.concatenate(label_gen).astype(np.float32)\n    print(label_array.shape)\n    print(label_array)\n    \n    return seq_array, label_array, test_df, sequence_length, sequence_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LSTM Model\n","metadata":{}},{"cell_type":"code","source":"def r2_keras(y_true, y_pred):\n    \"\"\"Coefficient of Determination \n    \"\"\"\n    SS_res =  K.sum(K.square( y_true - y_pred ))\n    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n\ndef lstm_train(seq_array, label_array, sequence_length):\n    # The first layer is an LSTM layer with 100 units followed by another LSTM layer with 50 units. \n    # Dropout is also applied after each LSTM layer to control overfitting. \n    # Final layer is a Dense output layer with single unit and linear activation since this is a regression problem.\n    nb_features = seq_array.shape[2]\n    nb_out = label_array.shape[1]\n\n    model = Sequential()\n    model.add(LSTM(\n             input_shape=(sequence_length, nb_features),\n             units=100,\n             return_sequences=True))\n    model.add(Dropout(0.2))\n    model.add(LSTM(\n              units=50,\n              return_sequences=False))\n    model.add(Dropout(0.2))\n    model.add(Dense(units=nb_out))\n    model.add(Activation(\"linear\"))\n    model.compile(loss='mean_squared_error', optimizer='rmsprop',metrics=['mae',r2_keras])\n\n    print(model.summary())\n\n    # fit the network # Commoly used 100 epoches but 50-60 are fine its an early cutoff \n    history = model.fit(seq_array, label_array, epochs=60, batch_size=200, validation_split=0.05, verbose=2)\n    #           callbacks = [keras.callbacks.EarlyStoping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n    #                        keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n    #           )\n\n    # list all data in history\n    print(history.history.keys())\n    \n    return model, history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model Evaluation on Test set\n","metadata":{}},{"cell_type":"code","source":"def lstm_test_evaluation_graphs(model, history, seq_array, label_array):\n    # summarize history for R^2\n    fig_acc = plt.figure(figsize=(10, 10))\n    plt.plot(history.history['r2_keras'])\n    plt.plot(history.history['val_r2_keras'])\n    plt.title('model r^2')\n    plt.ylabel('R^2')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    # fig_acc.savefig(\"model_r2.png\")\n\n    # summarize history for MAE\n    fig_acc = plt.figure(figsize=(10, 10))\n    plt.plot(history.history['mae'])\n    plt.plot(history.history['val_mae'])\n    plt.title('model MAE')\n    plt.ylabel('MAE')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    # fig_acc.savefig(\"model_mae.png\")\n\n    # summarize history for Loss\n    fig_acc = plt.figure(figsize=(10, 10))\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    # fig_acc.savefig(\"model_regression_loss.png\")\n\n    # training metrics\n    scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\n    print('\\nMAE: {}'.format(scores[1]))\n    print('\\nR^2: {}'.format(scores[2]))\n\n    y_pred = model.predict(seq_array,verbose=1, batch_size=200)\n    y_true = label_array\n\n    test_set = pd.DataFrame(y_pred )\n    test_set.head()\n    # test_set.to_csv('submit_train.csv', index = None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model Evaluation on Validation set","metadata":{}},{"cell_type":"code","source":"def lstm_valid_evaluation(lstm_test_df, model, sequence_length, sequence_cols):\n    # We pick the last sequence for each id in the test data\n    seq_array_test_last = [lstm_test_df[lstm_test_df['unit_number']==id][sequence_cols].values[-sequence_length:] \n                           for id in lstm_test_df['unit_number'].unique() if len(lstm_test_df[lstm_test_df['unit_number']==id]) >= sequence_length]\n\n    seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n\n    # Similarly, we pick the labels\n    y_mask = [len(lstm_test_df[lstm_test_df['unit_number']==id]) >= sequence_length for id in lstm_test_df['unit_number'].unique()]\n    label_array_test_last = lstm_test_df.groupby('unit_number')['RUL'].nth(-1)[y_mask].values\n    label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)\n\n    estimator = model\n\n    # test metrics\n    scores_test = estimator.evaluate(seq_array_test_last, label_array_test_last, verbose=2)\n    print('\\nMAE: {}'.format(scores_test[1]))\n    print('\\nR^2: {}'.format(scores_test[2]))\n\n    y_pred_test = estimator.predict(seq_array_test_last)\n    y_true_test = label_array_test_last\n\n    test_set = pd.DataFrame(y_pred_test)\n    print(test_set.head())\n\n    # Plot in blue color the predicted data and in green color the\n    # actual data to verify visually the accuracy of the model.\n    fig_verify = plt.figure(figsize=(10, 5))\n    plt.plot(y_pred_test)\n    plt.plot(y_true_test, color=\"orange\")\n    plt.title('prediction')\n    plt.ylabel('value')\n    plt.xlabel('row')\n    plt.legend(['predicted', 'actual data'], loc='upper left')\n    plt.show()\n    # fig_verify.savefig(\"model_regression_verify.png\")\n    return scores_test[1], scores_test[2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### References of LSTM\n\n\n- [1] Deep Learning for Predictive Maintenance https://github.com/Azure/lstms_for_predictive_maintenance/blob/master/Deep%20Learning%20Basics%20for%20Predictive%20Maintenance.ipynb\n- [2] Predictive Maintenance: Step 2A of 3, train and evaluate regression models https://gallery.cortanaintelligence.com/Experiment/Predictive-Maintenance-Step-2A-of-3-train-and-evaluate-regression-models-2\n- [3] A. Saxena and K. Goebel (2008). \"Turbofan Engine Degradation Simulation Data Set\", NASA Ames Prognostics Data Repository (https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan), NASA Ames Research Center, Moffett Field, CA \n- [4] Understanding LSTM Networks http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n- [5] https://github.com/umbertogriffo/Predictive-Maintenance-using-LSTM","metadata":{}},{"cell_type":"markdown","source":"### Function for creating and training models using the \"Random forest\" and \"XGBoost\" algorithms\n","metadata":{}},{"cell_type":"code","source":"#function for creating and training models using the \"Random forest\" and \"XGBoost\" algorithms\ndef train_models(data,model = 'FOREST'):\n    \n    if model != 'LSTM':\n        X = data.iloc[:,:14].to_numpy() \n        Y = data.iloc[:,14:].to_numpy()\n        Y = np.ravel(Y)\n\n    if model == 'FOREST':\n         #  parameters for models are selected in a similar cycle, with the introduction \n         # of an additional param parameter into the function:\n         #for i in range(1,11):\n         #     xgb = train_models(train_df,param=i,model=\"XGB\",)\n         #     y_xgb_i_pred = xgb.predict(X_001_test)\n         #     print(f'param = {i}')\n         #     score_func(y_true,y_xgb_i_pred)\n        model = RandomForestRegressor(n_estimators=70, max_features=7, max_depth=5, n_jobs=-1, random_state=1)\n        model.fit(X,Y)\n        return model\n    \n    elif model == 'XGB':\n        model = xgboost.XGBRegressor(n_estimators=110, learning_rate=0.018, gamma=0, subsample=0.8,\n                           colsample_bytree=0.5, max_depth=3,silent=True)\n        model.fit(X,Y)\n        return model\n    \n    elif model == 'LSTM':\n        seq_array, label_array, lstm_test_df, sequence_length, sequence_cols = lstm_data_preprocessing(data[0], data[1], data[2])\n        model_instance, history = lstm_train(seq_array, label_array, sequence_length)\n        return model_instance, history, lstm_test_df, seq_array, label_array, sequence_length, sequence_cols\n            \n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function for joint display of real and predicted values\n\ndef plot_result(y_true,y_pred):\n    rcParams['figure.figsize'] = 12,10\n    plt.plot(y_pred)\n    plt.plot(y_true)\n    plt.tick_params(axis='x', which='both', bottom=False, top=False,labelbottom=False)\n    plt.ylabel('RUL')\n    plt.xlabel('training samples')\n    plt.legend(('Predicted', 'True'), loc='upper right')\n    plt.title('COMPARISION OF Real and Predicted values')\n    plt.show()\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare test data for classification\nonly the features used in the training are needed and a line with the maximum value for this engine time_in_cycles (last)","metadata":{}},{"cell_type":"code","source":"fd_001_test.drop(columns=['Nf_dmd','PCNfR_dmd','P2','T2','TRA','farB','epr'],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_max = fd_001_test.groupby('unit_number')['time_in_cycles'].max().reset_index()\ntest_max.columns = ['unit_number','max']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fd_001_test = fd_001_test.merge(test_max, on=['unit_number'], how='left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = fd_001_test[fd_001_test['time_in_cycles'] == fd_001_test['max']].reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop(columns=['index','max','unit_number','setting_1','setting_2','P15','NRc'],inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_001_test = test.to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_001_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fd_001_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction of the final result for all engines","metadata":{}},{"cell_type":"markdown","source":"\n#### Let's train the model on training data without the deleted properties 'unit_number', 'setting_1', 'setting_2', 'P15', 'NRc'","metadata":{}},{"cell_type":"code","source":"model_1 = train_models(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model_1.predict(X_001_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RUL = pd.read_csv(\"/kaggle/input/nasa-cmaps/CMaps/RUL_FD001.txt\",sep=\" \",header=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = RUL[0].to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RUL.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Competitive score, the average absolute error, the root mean square error and the coefficient of determination of the resulting model:","metadata":{}},{"cell_type":"code","source":"RF_individual_scorelst = score_func(y_true, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_result(y_true,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LSTM funtion calling","metadata":{}},{"cell_type":"code","source":"train_df_lstm = pd.concat([unit_number, train_df], axis=1)\nmodel, history, lstm_test_df, seq_array, label_array, sequence_length, sequence_cols = train_models([train_df_lstm, fd_001_test, RUL.copy()], \"LSTM\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_test_evaluation_graphs(model, history, seq_array, label_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAE, R2 = lstm_valid_evaluation(lstm_test_df, model, sequence_length, sequence_cols)\n# mae, rmse, r2\nLSTM_individual_scorelst = [round(MAE,2), 0, round(R2,2)*100]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#### Let’s try to improve the algorithm for predicting the results, for this we will train the model each time again for each individual prediction, discarding in the training array the values ​​on the timeline (time_in_cycles) are smaller than the last value in the fd_001_test array, that is, lower than the value for which RUL should be predicted (remaining useful life)","metadata":{}},{"cell_type":"code","source":"# to discard values in the training array, use the factor parameter in\n# prepare_train_data functions, in test_data are samples prepared for recognition, in the first column of which\n# - value of time in cycles for which RUL is predicted\ndef single_train(test_data,train_data,algorithm):\n    y_single_pred = []\n    for sample in tqdm(test_data):\n        time.sleep(0.01)\n        single_train_df = prepare_train_data(train_data, factor = sample[0])\n        single_train_df.drop(columns = ['unit_number','setting_1','setting_2','P15','NRc'],inplace = True)\n        model = train_models(single_train_df,algorithm)\n        y_p = model.predict(sample.reshape(1,-1))[0]\n        y_single_pred.append(y_p)\n    y_single_pred = np.array(y_single_pred)\n    return y_single_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_single_pred = single_train(X_001_test,fd_001_train,'FOREST')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Display the results.","metadata":{}},{"cell_type":"code","source":"plot_result(y_true,y_single_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Competitive score, average absolute error and coefficient of determination of the improved model","metadata":{}},{"cell_type":"code","source":"RF_SingleTrain_scorelst = score_func(y_true, y_single_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Using a modified algorithm with individual training and prediction, it was possible to significantly reduce the MAE and increase the R2 score","metadata":{}},{"cell_type":"markdown","source":"#### Since the sensor data is very noisy, we will try the following approach to improve the prediction: we will make predictions based on not one (last) “slice” of the sensor values, as was done above, but some optimized (for example, by determination coefficient or mean absolute error) number of previous breaking values. To display the final value of RUL, we use the average value of all predictions","metadata":{}},{"cell_type":"code","source":"def prepare_test_data(fd_001_test,n=0):\n    test = fd_001_test[fd_001_test['time_in_cycles'] == fd_001_test['max'] - n].reset_index()\n    test.drop(columns=['index','max','unit_number','setting_1','setting_2','P15','NRc'],inplace = True)\n    X_return = test.to_numpy()\n    return X_return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N=5\ny_n_pred = y_single_pred\nfor i in range(1,N):\n    X_001_test = prepare_test_data(fd_001_test,i)\n    y_single_i_pred = single_train(X_001_test,fd_001_train,'FOREST')    \n    y_n_pred = np.vstack((y_n_pred,y_single_i_pred))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We calculate the average value of predictions for each engine","metadata":{}},{"cell_type":"code","source":"y_multi_pred = np.mean(y_n_pred,axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RF_5avg_scorelst = score_func(y_true,y_multi_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We display the results for the average of 5 predictions","metadata":{}},{"cell_type":"code","source":"plot_result(y_true,y_multi_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N=10\n\n# In order not to recalculate the average result for 5 predictions, the stored value y_multi_pred\n# is entered in y_n_pred, then the predictions for 5,6,7 .... lines from the last for the given engine\ny_n_pred = y_multi_pred\nfor i in range(5,N):\n    X_001_test = prepare_test_data(fd_001_test,i)\n    y_single_i_pred = single_train(X_001_test,fd_001_train,'FOREST')    \n    y_n_pred = np.vstack((y_n_pred,y_single_i_pred))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_multi_pred_10 = np.mean(y_n_pred,axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_func(y_true,y_multi_pred_10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nWe display the results for an average of 10 predictions","metadata":{}},{"cell_type":"code","source":"plot_result(y_true,y_multi_pred_10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Obviously, with a further increase in the number of predictions for deriving the average, the quality of the model’s answers does not improve, in the future we will use y_multi_pred (the average of 5 individual predictions)","metadata":{}},{"cell_type":"markdown","source":"### Compare the results with another model - XGBoost","metadata":{}},{"cell_type":"code","source":"xgb = train_models(train_df,model=\"XGB\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_xgb_pred = xgb.predict(X_001_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XGB_individual_scorelst = score_func(y_true,y_xgb_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to regression algorithm estimation metrics, the result is worse than for a \"random forest\"\nMetrics for RandomForestRegressor\n\nCompetitive Score 1057.2\n\n mean absolute error 19.25\n \n root mean squared error 24.45219826518671\n \n R2 score 0.65","metadata":{}},{"cell_type":"code","source":"plot_result(y_true,y_xgb_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Individual predictions for XGBoost:","metadata":{}},{"cell_type":"code","source":"y_single_xgb_pred = single_train(X_001_test,fd_001_train,'XGB')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XGB_SingleTrain_scorelst = score_func(y_true,y_single_xgb_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_result(y_true,y_single_xgb_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N=5\ny_n_pred = y_single_xgb_pred\nfor i in range(1,N):\n    X_001_test = prepare_test_data(fd_001_test,i)\n    y_single_i_pred = single_train(X_001_test,fd_001_train,'XGB')    \n    y_n_pred = np.vstack((y_n_pred,y_single_i_pred)) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_5_pred_xgb = np.mean(y_n_pred,axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XGB_5avg_scorelst = score_func(y_true,y_5_pred_xgb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similarly, all metrics, except for the competitive error function (compared to the joint prediction) have improved their value","metadata":{}},{"cell_type":"code","source":"plot_result(y_true,y_5_pred_xgb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bar plots for comparision\ndef Bar_Plots(RF_score_lst, XGB_score_lst, LSTM_score_lst=0):\n    hue = [\"mae\",\"rmse\", \"r2\"]\n    \n    if LSTM_score_lst != 0: \n        df = pd.DataFrame(zip(hue*3, [\"RFRegrssor\"]*3+[\"LSTM\"]*3+[\"XGBRegressor\"]*3, RF_score_lst+LSTM_score_lst+XGB_score_lst), columns=[\"Parameters\", \"Models\", \"Scores\"])\n    else:\n        df = pd.DataFrame(zip(hue*3, [\"RFRegrssor\"]*3+[\"XGBRegressor\"]*3, RF_score_lst+XGB_score_lst), columns=[\"Parameters\", \"Models\", \"Scores\"])\n\n    print(df.head(10))\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=\"Models\", y=\"Scores\", hue=\"Parameters\", data=df)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Individual Paramters comparision\n# LSTM_individual_scorelst = [17.36, 0, 75] # Comment this line when lstm runs 60 epoches\nBar_Plots(RF_individual_scorelst, XGB_individual_scorelst, LSTM_individual_scorelst)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Single Train comparison\nBar_Plots(RF_SingleTrain_scorelst, XGB_SingleTrain_scorelst)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Avg of 5 comparision\nBar_Plots(RF_5avg_scorelst, XGB_5avg_scorelst)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare = pd.DataFrame(list(zip(y_true, y_pred, y_single_pred,y_multi_pred,y_multi_pred_10,y_xgb_pred,y_single_xgb_pred)), \n               columns =['True','Forest_Predicted','Forest_Single_predicted','multi_5','multi_10'\n                         ,'XGBoost','XGBoost_single']) \ncompare['unit_number'] = compare.index + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare['Predicted_error'] = compare['True'] - compare['Forest_Predicted']\ncompare['Single_pred_error'] = compare['True'] - compare['Forest_Single_predicted']\ncompare['multi_5_error'] = compare['True'] - compare['multi_5']\ncompare['multi_10_error'] = compare['True'] - compare['multi_10']\ncompare['xgb_error'] = compare['True'] - compare['XGBoost']\ncompare['xgb_single_error'] = compare['True'] - compare['XGBoost_single']\nax1 = compare.plot(subplots=True, sharex=True, figsize=(20,20))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Errors in all algorithms are strongly correlated, to further improve the forecasts of the algorithm, pre-processing of training and possibly test data is necessary to eliminate outliers","metadata":{}},{"cell_type":"markdown","source":"To obtain practical value from the data, we use binary classification algorithms for maintenance planning, calculate what profit (or loss) analysis and maintenance planning can bring for a hypothetical airline\n\nhttps://github.com/Samimust/predictive-maintenance/blob/master/Model%20Selection%20-%20Binary%20Classifiaction.ipynb","metadata":{}},{"cell_type":"markdown","source":"\nLet's create a classifier that will answer the question: \"Current engine resource more or less than 10 cycles\"? It is assumed that this is sufficient time to prepare and start maintenance.","metadata":{}},{"cell_type":"markdown","source":"## Expected Value Calculation:\nBased on the book: Data Science for Business, https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/1449361323 . Expected Value is a method to compare different classification models by constructing cost-benefit matrix in line with the confusion matrix, and then convert model performance to a single monetary value by multiplying confusion matrix into the cost-benefit matrix.\n\nCost-benefit matrix should be designed by domain expert. Let us assume the following:\n\nTrue Positive (TP) has benefit of USD 300K: engines that need maintenance and correctly selected by the model.\n\nTrue Negative (TN) has benefit of USD 0K: engines that are OK and not selected by the model.\n\nFalse Positive (FP) has cost of USD -100K: engines that are OK but selected by the model.\n\nFalse Negative (FN) has cost of USD -200K: engines that need maintenance but not selected by the model.","metadata":{}},{"cell_type":"code","source":"# formation of the target variable label, TTF - time to failure\nTTF = 10\ntrain_df['label'] = np.where(train_df['RUL'] <= TTF, 1, 0 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"formation of the target variable label, TTF - time to failure","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nWe display the scattering diagram of two parameters with a separation according to the target attribute","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x=\"Nc\", y=\"T50\", hue=\"label\", data=train_df)\nplt.title('Scatter patter Nc or T50')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare data for classification","metadata":{}},{"cell_type":"code","source":"# exclude the RUL property and form an array of attributes and the target variable\nX_class = train_df.iloc[:,:14].to_numpy() \nY_class = train_df.iloc[:,15:].to_numpy()\nY_class = np.ravel(Y_class)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Class balancing to improve classifier performance\nfrom imblearn.over_sampling import RandomOverSampler\n#from imblearn.under_sampling import RandomUnderSampler\nros = RandomOverSampler(random_state=0)\nros.fit(X_class, Y_class)\nX_resampled, y_resampled = ros.fit_sample(X_class, Y_class)\nprint('The number of elements before the operation:', len(X_class))\nprint('The number of elements after the operation:', len(X_resampled))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we divide the data into the training sample and the test one, \n#test_size = 0.2 sets the proportion of the test sample = 20%\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size = 0.2,random_state = 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forest = RandomForestClassifier(n_estimators=70 ,max_depth = 8, random_state=193)\nforest.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xgb = XGBClassifier()\nmodel_xgb.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classificator_score(y_,y_p):\n    print(f' accuracy score {round(accuracy_score(y_, y_p),2)}')\n    print(f' precision score {round(precision_score(y_, y_p),2)}')\n    print(f' recall score {round(recall_score(y_, y_p),2)}')\n    print(f' F1 score {round(f1_score(y_, y_p),2)}')\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Metrics for RandomForestClassifier","metadata":{}},{"cell_type":"code","source":"classificator_score(y_test,forest.predict(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_xgb_pred = model_xgb.predict(X_001_test)\nclassificator_score(y_test,model_xgb.predict(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_001_test = test.to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we will form a generalized table for predicted and correct values","metadata":{}},{"cell_type":"code","source":"# prediction for X_001_test, time to failure = TTF = 10\npredicted = pd.DataFrame()\npredicted ['forest'] =  forest.predict(X_001_test)\npredicted['XGB'] = y_xgb_pred\npredicted['RUL']=RUL[0]\npredicted['true_label'] = np.where(y_true <= TTF, 1, 0 )\npredicted['unit_number'] = predicted.index + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# true TTF values <= 10\npredicted[predicted['true_label'] == 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# engines for which the RandomForest classification algorithm gave incorrect predictions\npredicted[predicted['true_label'] != predicted['forest']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# engines for which the XGBoost classification algorithm gave incorrect predictions\npredicted[predicted['true_label'] != predicted['XGB']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true_class = np.where(y_true <= TTF, 1, 0 )\ny_pred_class = predicted['forest'].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function for calculating expected profits as described above","metadata":{}},{"cell_type":"code","source":"def expected_profit(y_true,y_pred):\n    TP=0\n    FP=0\n    TN=0\n    FN=0\n    for i in range(len(y_true)):\n        if (y_true[i] != y_pred[i]) & (y_pred[i] == 1):\n            FP += 1\n        elif (y_true[i] != y_pred[i]) & (y_pred[i] == 0):\n            FN += 1\n        elif (y_true[i] == y_pred[i]) & (y_pred[i] == 0):\n            TN += 1\n        else:\n            TP += 1\n    print(f'TP ={TP}, TN = {TN}, FP = {FP}, FN = {FN}')\n    print (f'expected profit {(300 * TP - 200 * FN - 100 * FP) * 1000}')\n    return \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def confusion_matrix(actual, predicted):\n    plt.figure(figsize=(5,5))\n    sns.heatmap(sklearn.metrics.confusion_matrix(actual,predicted),annot=True,fmt='.5g')\n    plt.ylabel('actual class')\n    plt.xlabel('predicted class')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# forest\nexpected_profit(y_true_class,y_pred_class)\nconfusion_matrix(y_true_class, y_pred_class)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Xgboost\nexpected_profit(y_true_class,y_xgb_pred)\nconfusion_matrix(y_true_class, y_xgb_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ROC(Receiver Operating Characteristic) Curve ","metadata":{}},{"cell_type":"code","source":"fpr_xgb, tpr_xgb, _ = metrics.roc_curve(y_true_class,  y_xgb_pred)                      \nfpr_RF, tpr_RF, _ = metrics.roc_curve(y_true_class,  y_pred_class)\nauc_xgb = metrics.auc(fpr_xgb,  tpr_xgb)\nauc_RF = metrics.auc(fpr_RF,  tpr_RF)\n\nplt.figure(figsize=(10, 6))\nplt.plot(fpr_xgb,tpr_xgb, label='ROC curve of XGB(area = %0.2f)' % auc_xgb)\nplt.plot(fpr_RF,tpr_RF, label='ROC curve of RF(area = %0.2f)' % auc_RF)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic (ROC)')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion: the proposed classification algorithms show useful results on test data and can be used to obtain cost savings during preventive maintenance of aircraft engines, to estimate the approximate remaining engine life (if the corresponding error is permissible under specific conditions) it can be used in conjunction with the regression algorithms described above","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}